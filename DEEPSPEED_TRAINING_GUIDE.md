# ğŸš€ GPT-2 XL DeepSpeed è®­ç»ƒå®Œæ•´æŒ‡å—

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ ¸å¿ƒæ–‡ä»¶è¯´æ˜](#æ ¸å¿ƒæ–‡ä»¶è¯´æ˜)
- [é…ç½®è¯¦è§£](#é…ç½®è¯¦è§£)
- [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
- [æ¨¡å‹ä¿å­˜ä¸åŠ è½½](#æ¨¡å‹ä¿å­˜ä¸åŠ è½½)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)

---

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä½¿ç”¨ **DeepSpeed ZeRO-2** åœ¨å¤šGPUä¸Šè®­ç»ƒ **GPT-2 XL (1.5Bå‚æ•°)** æ¨¡å‹çš„å®Œæ•´è§£å†³æ–¹æ¡ˆã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

- âœ… **DeepSpeed ZeRO-2** - å†…å­˜ä¼˜åŒ–ï¼Œæ”¯æŒå¤§æ¨¡å‹è®­ç»ƒ
- âœ… **å¤šGPUå¹¶è¡Œ** - 4x V100-32GB GPU
- âœ… **æ··åˆç²¾åº¦è®­ç»ƒ** - FP16ï¼ŒåŠ é€Ÿè®­ç»ƒ
- âœ… **åˆ†å¸ƒå¼è¯„ä¼°** - å®æ—¶ç›‘æ§è®­ç»ƒå’ŒéªŒè¯loss
- âœ… **æ£€æŸ¥ç‚¹ä¿å­˜** - è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹å’Œè®­ç»ƒè¿›åº¦
- âœ… **å®Œæ•´æ–‡æ¡£** - è¯¦ç»†çš„ä»£ç æ³¨é‡Šå’Œä½¿ç”¨è¯´æ˜

### ğŸ“Š æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ¨¡å‹å¤§å° | 1.5B å‚æ•° |
| GPUæ•°é‡ | 4x V100-32GB |
| æ¯GPUå†…å­˜ | 15-16 GB |
| è®­ç»ƒé€Ÿåº¦ | ~303 ms/iteration |
| è¯„ä¼°é€Ÿåº¦ | ~2.7 s/evaluation |
| æœ‰æ•ˆbatch size | 32 (1Ã—4Ã—32) |

---

## ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚

- **GPU**: è‡³å°‘ 2 ä¸ª NVIDIA GPU
  - æ¨è: 4x V100 (32GB) æˆ– A100
  - æœ€ä½: 2x RTX 3090 (24GB)
- **æ˜¾å­˜**: æ¯ä¸ªGPUè‡³å°‘ 16GB
- **CPU**: å¤šæ ¸å¤„ç†å™¨ï¼ˆæ¨è16æ ¸ä»¥ä¸Šï¼‰
- **å†…å­˜**: è‡³å°‘ 64GB RAM
- **å­˜å‚¨**: è‡³å°‘ 50GB å¯ç”¨ç©ºé—´

### è½¯ä»¶è¦æ±‚

```bash
# Python ç¯å¢ƒ
Python >= 3.8

# æ ¸å¿ƒä¾èµ–
torch >= 1.12.0
deepspeed >= 0.7.0
numpy
transformers (å¯é€‰ï¼Œç”¨äºåŠ è½½é¢„è®­ç»ƒæ¨¡å‹)
```

### å®‰è£…ä¾èµ–

```bash
# å®‰è£… PyTorchï¼ˆæ ¹æ®æ‚¨çš„CUDAç‰ˆæœ¬ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£… DeepSpeed
pip install deepspeed

# å®‰è£…å…¶ä»–ä¾èµ–
pip install numpy transformers tiktoken
```

---

## å¿«é€Ÿå¼€å§‹

### ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡æ•°æ®

```bash
cd /data/workspace/switch/nanoGPT

# å‡†å¤‡ Shakespeare æ•°æ®é›†
python data/shakespeare/prepare.py
```

è¿™ä¼šç”Ÿæˆï¼š
- `data/shakespeare/train.bin` - è®­ç»ƒæ•°æ®
- `data/shakespeare/val.bin` - éªŒè¯æ•°æ®
- `data/shakespeare/meta.pkl` - å…ƒæ•°æ®

### ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥é…ç½®

æŸ¥çœ‹å¹¶ç¡®è®¤é…ç½®æ–‡ä»¶ï¼š

```bash
# æŸ¥çœ‹ DeepSpeed é…ç½®
cat ds_config_zero2.json

# æŸ¥çœ‹è®­ç»ƒè„šæœ¬é…ç½®ï¼ˆå‰50è¡Œï¼‰
head -50 train_deepspeed.py
```

### ç¬¬ä¸‰æ­¥ï¼šå¯åŠ¨è®­ç»ƒ

**æ–¹æ³•1ï¼šä½¿ç”¨ä¾¿æ·è„šæœ¬ï¼ˆæ¨èï¼‰**

```bash
chmod +x run_deepspeed_xl.sh
./run_deepspeed_xl.sh
```

**æ–¹æ³•2ï¼šç›´æ¥ä½¿ç”¨ DeepSpeed å‘½ä»¤**

```bash
deepspeed --num_gpus=4 train_deepspeed.py
```

**æ–¹æ³•3ï¼šæŒ‡å®šç‰¹å®šGPU**

```bash
# åªä½¿ç”¨GPU 0å’Œ1
CUDA_VISIBLE_DEVICES=0,1 deepspeed --num_gpus=2 train_deepspeed.py
```

### ç¬¬å››æ­¥ï¼šç›‘æ§è®­ç»ƒ

```bash
# å®æ—¶æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi

# æŸ¥çœ‹è®­ç»ƒè¾“å‡ºï¼ˆå¦‚æœåå°è¿è¡Œï¼‰
tail -f nohup.out

# æˆ–è€…ä½¿ç”¨ tensorboardï¼ˆå¦‚æœé…ç½®äº†ï¼‰
tensorboard --logdir=./runs
```

---

## æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

### ğŸ“„ train_deepspeed.py

**ä¸»è®­ç»ƒè„šæœ¬** - å®ç°äº†å®Œæ•´çš„DeepSpeedè®­ç»ƒæµç¨‹

#### æ–‡ä»¶ç»“æ„

```python
# 1. å¯¼å…¥å’Œé…ç½® (è¡Œ1-58)
- å¯¼å…¥å¿…è¦çš„åº“
- å®šä¹‰è®­ç»ƒè¶…å‚æ•°
- è§£æå‘½ä»¤è¡Œå‚æ•°

# 2. åˆ†å¸ƒå¼åˆå§‹åŒ– (è¡Œ59-90)
- è·å–rankå’Œworld_size
- è®¾ç½®CUDAè®¾å¤‡
- åˆå§‹åŒ–éšæœºç§å­

# 3. æ•°æ®åŠ è½½ (è¡Œ91-108)
- å®šä¹‰ get_batch() å‡½æ•°
- åŠ è½½è®­ç»ƒå’ŒéªŒè¯æ•°æ®

# 4. æ¨¡å‹åˆå§‹åŒ– (è¡Œ109-166)
- ä»é¢„è®­ç»ƒæƒé‡åŠ è½½ GPT-2 XL
- åˆ›å»º PyTorch AdamW ä¼˜åŒ–å™¨
- åˆå§‹åŒ– DeepSpeed å¼•æ“

# 5. è¯„ä¼°å‡½æ•° (è¡Œ167-216)
- åˆ†å¸ƒå¼è¯„ä¼°å®ç°
- æ”¯æŒ train/val loss è®¡ç®—
- all_reduce åŒæ­¥ç»“æœ

# 6. è®­ç»ƒå¾ªç¯ (è¡Œ217-279)
- ä¸»è®­ç»ƒå¾ªç¯
- è¯„ä¼°å’Œæ£€æŸ¥ç‚¹ä¿å­˜
- è¿›åº¦è¾“å‡º
```

#### å…³é”®é…ç½®å‚æ•°

```python
# è®­ç»ƒé…ç½®
max_iters = 20                    # æ€»è¿­ä»£æ¬¡æ•°
batch_size = 1                    # æ¯GPUçš„batch size
gradient_accumulation_steps = 32  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
learning_rate = 3e-5              # å­¦ä¹ ç‡

# è¯„ä¼°é…ç½®
eval_interval = 5                 # æ¯5æ­¥è¯„ä¼°ä¸€æ¬¡
eval_iters = 20                   # æ¯æ¬¡è¯„ä¼°20ä¸ªbatch

# æ¨¡å‹é…ç½®
init_from = 'gpt2-xl'            # ä»GPT-2 XLåˆå§‹åŒ–
block_size = 1024                 # åºåˆ—é•¿åº¦
dtype = 'float16'                 # ä½¿ç”¨FP16

# DeepSpeedé…ç½®
deepspeed_config = 'ds_config_zero2.json'
```

### ğŸ“„ ds_config_zero2.json

**DeepSpeed é…ç½®æ–‡ä»¶** - å®šä¹‰ZeROä¼˜åŒ–ç­–ç•¥

```json
{
  // åŸºç¡€é…ç½®
  "train_micro_batch_size_per_gpu": 1,
  "gradient_accumulation_steps": 32,
  "gradient_clipping": 1.0,
  
  // ZeRO Stage 2 ä¼˜åŒ–
  "zero_optimization": {
    "stage": 2,                    // ZeRO-2: åˆ†ç‰‡ä¼˜åŒ–å™¨å’Œæ¢¯åº¦
    "allgather_partitions": true,
    "overlap_comm": true,          // é‡å é€šä¿¡å’Œè®¡ç®—
    "contiguous_gradients": true   // è¿ç»­æ¢¯åº¦å­˜å‚¨
  },
  
  // æ··åˆç²¾åº¦è®­ç»ƒ
  "fp16": {
    "enabled": true,               // å¯ç”¨FP16
    "loss_scale": 0,               // åŠ¨æ€loss scaling
    "initial_scale_power": 16
  }
}
```

#### é…ç½®å‚æ•°è¯¦è§£

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| `train_micro_batch_size_per_gpu` | æ¯ä¸ªGPUçš„batch size | 1 |
| `gradient_accumulation_steps` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° | 32 |
| `gradient_clipping` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ | 1.0 |
| `stage` | ZeROä¼˜åŒ–çº§åˆ« (0/1/2/3) | 2 |
| `overlap_comm` | é€šä¿¡è®¡ç®—é‡å  | true |
| `fp16.enabled` | å¯ç”¨æ··åˆç²¾åº¦ | true |

### ğŸ“„ run_deepspeed_xl.sh

**è®­ç»ƒå¯åŠ¨è„šæœ¬** - è‡ªåŠ¨åŒ–è®­ç»ƒæµç¨‹

```bash
#!/bin/bash
# åŠŸèƒ½ï¼š
# 1. æ£€æŸ¥ä¾èµ–ï¼ˆDeepSpeedã€é…ç½®æ–‡ä»¶ã€æ•°æ®ï¼‰
# 2. æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯
# 3. å¯åŠ¨ DeepSpeed è®­ç»ƒ
# 4. å¤„ç†è®­ç»ƒç»“æœ

# ä½¿ç”¨æ–¹æ³•ï¼š
chmod +x run_deepspeed_xl.sh
./run_deepspeed_xl.sh
```

---

## é…ç½®è¯¦è§£

### è®­ç»ƒè¶…å‚æ•°

#### batch_size å’Œæ¢¯åº¦ç´¯ç§¯

```python
# æœ‰æ•ˆ batch size è®¡ç®—ï¼š
effective_batch_size = batch_size Ã— num_gpus Ã— gradient_accumulation_steps
                     = 1 Ã— 4 Ã— 32
                     = 128

# ä¸ºä»€ä¹ˆè¿™æ ·è®¾ç½®ï¼Ÿ
batch_size = 1                    # GPUå†…å­˜é™åˆ¶
gradient_accumulation_steps = 32  # è¾¾åˆ°ç†æƒ³çš„batch size
```

**è°ƒä¼˜å»ºè®®ï¼š**

| GPUå†…å­˜ | batch_size | gradient_accumulation_steps | æœ‰æ•ˆbatch_size |
|---------|------------|----------------------------|---------------|
| 16GB | 1 | 64 | 256 |
| 24GB | 2 | 32 | 256 |
| 32GB | 2 | 32 | 256 |
| 40GB+ | 4 | 16 | 256 |

#### å­¦ä¹ ç‡

```python
learning_rate = 3e-5  # GPT-2 XL å¾®è°ƒæ¨èå€¼

# ä¸åŒä»»åŠ¡çš„å»ºè®®ï¼š
# - é¢„è®­ç»ƒ: 6e-4
# - å¾®è°ƒ: 1e-5 åˆ° 5e-5
# - é¢†åŸŸé€‚åº”: 3e-5 åˆ° 1e-4
```

**å­¦ä¹ ç‡è°ƒåº¦ï¼ˆå¯é€‰ï¼‰ï¼š**

```python
# æ·»åŠ å­¦ä¹ ç‡é¢„çƒ­å’Œè¡°å‡
warmup_iters = 100
lr_decay_iters = 1000
min_lr = learning_rate / 10

# åœ¨è®­ç»ƒå¾ªç¯ä¸­ï¼š
if iter_num < warmup_iters:
    lr = learning_rate * (iter_num + 1) / warmup_iters
elif iter_num < lr_decay_iters:
    decay_ratio = (iter_num - warmup_iters) / (lr_decay_iters - warmup_iters)
    lr = min_lr + (learning_rate - min_lr) * (1 - decay_ratio)
else:
    lr = min_lr

for param_group in optimizer.param_groups:
    param_group['lr'] = lr
```

### DeepSpeed ZeRO é…ç½®

#### ZeRO Stage å¯¹æ¯”

| Stage | åˆ†ç‰‡å†…å®¹ | å†…å­˜èŠ‚çœ | é€šä¿¡å¼€é”€ | æ¨èåœºæ™¯ |
|-------|---------|---------|---------|---------|
| **0** | æ—  | 0% | æœ€ä½ | å°æ¨¡å‹ |
| **1** | ä¼˜åŒ–å™¨çŠ¶æ€ | ~25% | ä½ | ä¸­ç­‰æ¨¡å‹ |
| **2** | ä¼˜åŒ–å™¨+æ¢¯åº¦ | ~50% | ä¸­ç­‰ | **GPT-2 XL** âœ… |
| **3** | å…¨éƒ¨çŠ¶æ€ | ~90% | é«˜ | è¶…å¤§æ¨¡å‹ |

**ä¸ºä»€ä¹ˆé€‰æ‹© ZeRO-2ï¼Ÿ**

- âœ… è¶³å¤Ÿçš„å†…å­˜èŠ‚çœï¼ˆ15-16GB/GPU vs 33GBå•GPUï¼‰
- âœ… åˆç†çš„é€šä¿¡å¼€é”€
- âœ… ä¸éœ€è¦CPU offloading
- âœ… æœ€ç¨³å®šå¯é 

#### å†…å­˜ä¼˜åŒ–ç­–ç•¥

```
å•GPUå†…å­˜éœ€æ±‚ï¼ˆFP16ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç»„ä»¶                â”‚ å†…å­˜      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ¨¡å‹å‚æ•°            â”‚ 3.0 GB   â”‚
â”‚ æ¢¯åº¦                â”‚ 3.0 GB   â”‚
â”‚ ä¼˜åŒ–å™¨çŠ¶æ€ (Adam)   â”‚ 12.0 GB  â”‚
â”‚ æ¿€æ´»å€¼              â”‚ 15.0 GB  â”‚
â”‚ å…¶ä»–                â”‚ 2.0 GB   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ€»è®¡                â”‚ 35.0 GB  â”‚ âŒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ZeRO-2 ä¼˜åŒ–åï¼ˆ4 GPUï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç»„ä»¶                â”‚ å†…å­˜/GPU  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ¨¡å‹å‚æ•°            â”‚ 3.0 GB   â”‚ (å¤åˆ¶)
â”‚ æ¢¯åº¦                â”‚ 0.75 GB  â”‚ (åˆ†ç‰‡)
â”‚ ä¼˜åŒ–å™¨çŠ¶æ€          â”‚ 3.0 GB   â”‚ (åˆ†ç‰‡)
â”‚ æ¿€æ´»å€¼              â”‚ 15.0 GB  â”‚
â”‚ å…¶ä»–                â”‚ 2.0 GB   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ€»è®¡                â”‚ 23.75 GB â”‚ âœ…
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

èŠ‚çœ: 35 - 23.75 = 11.25 GB (32%)
```

---

## è®­ç»ƒæµç¨‹

### å®Œæ•´è®­ç»ƒæµç¨‹å›¾

```
å¼€å§‹
  â†“
å‡†å¤‡æ•°æ® (prepare.py)
  â†“
åŠ è½½é…ç½®å’Œæ¨¡å‹
  â†“
åˆå§‹åŒ– DeepSpeed
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è®­ç»ƒå¾ªç¯å¼€å§‹       â”‚
â”‚                     â”‚
â”‚  iter 0, 5, 10...  â”‚
â”‚   â†“                â”‚
â”‚  è¯„ä¼° (estimate_loss) â”‚
â”‚   â”œâ”€ train loss    â”‚
â”‚   â””â”€ val loss      â”‚
â”‚   â†“                â”‚
â”‚  ä¿å­˜æ£€æŸ¥ç‚¹ï¼Ÿ       â”‚
â”‚                     â”‚
â”‚  iter 1, 2, 3...   â”‚
â”‚   â†“                â”‚
â”‚  å‰å‘ä¼ æ’­           â”‚
â”‚   â†“                â”‚
â”‚  åå‘ä¼ æ’­           â”‚
â”‚   â†“                â”‚
â”‚  æ¢¯åº¦ç´¯ç§¯ (32 steps) â”‚
â”‚   â†“                â”‚
â”‚  ä¼˜åŒ–å™¨æ›´æ–°         â”‚
â”‚   â†“                â”‚
â”‚  æ‰“å°è¿›åº¦           â”‚
â”‚                     â”‚
â”‚  ç»§ç»­ä¸‹ä¸€è½®ï¼Ÿ       â”‚
â”‚   â†“                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
ä¿å­˜æœ€ç»ˆæ¨¡å‹
  â†“
è®­ç»ƒå®Œæˆ
```

### è®­ç»ƒè¾“å‡ºç¤ºä¾‹

```bash
============================================================
å¼€å§‹è®­ç»ƒ GPT-2 XL (1.5B å‚æ•°) with DeepSpeed ZeRO-3
ä½¿ç”¨ 4 ä¸ª GPU
Batch size: 1
Gradient accumulation steps: 32
Max iterations: 20
============================================================

step 0: train loss 3.8287, val loss 3.7025
iter 0: loss 3.4785, time 3156.18ms
iter 1: loss 4.3047, time 303.49ms
iter 2: loss 3.4121, time 302.86ms
iter 3: loss 3.5371, time 302.84ms
iter 4: loss 4.1484, time 303.49ms

step 5: train loss 3.7234, val loss 3.6521  â† è¯„ä¼°
saving checkpoint to out-shakespeare-xl-deepspeed  â† ä¿å­˜
iter 5: loss 3.4785, time 2716.64ms
iter 6: loss 4.3047, time 303.67ms
...

============================================================
è®­ç»ƒå®Œæˆï¼
æœ€ç»ˆæ¨¡å‹ä¿å­˜åœ¨: out-shakespeare-xl-deepspeed
============================================================

ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹...
âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: out-shakespeare-xl-deepspeed/final/
```

### è®­ç»ƒé€Ÿåº¦åˆ†æ

```python
# æ™®é€šè®­ç»ƒè¿­ä»£: ~303ms
è®­ç»ƒæ­¥éª¤:
  - å‰å‘ä¼ æ’­: ~100ms
  - åå‘ä¼ æ’­: ~150ms
  - ä¼˜åŒ–å™¨æ›´æ–°: ~50ms
  - GPUåŒæ­¥: ~3ms

# è¯„ä¼°è¿­ä»£: ~2700ms
è¯„ä¼°æ­¥éª¤:
  - åˆ‡æ¢åˆ°evalæ¨¡å¼: ~10ms
  - 20æ¬¡å‰å‘ä¼ æ’­: ~2000ms (100ms Ã— 20)
  - all_reduceåŒæ­¥: ~50ms
  - åˆ‡æ¢å›trainæ¨¡å¼: ~10ms
  - æ­£å¸¸è®­ç»ƒ: ~300ms
  - å…¶ä»–å¼€é”€: ~330ms

# æ€»è®­ç»ƒæ—¶é—´ä¼°ç®—ï¼ˆ20 iterationsï¼‰:
æ™®é€šè¿­ä»£: 16 Ã— 0.3s = 4.8s
è¯„ä¼°è¿­ä»£: 4 Ã— 2.7s = 10.8s
æ€»è®¡: ~15.6s
```

---

## æ¨¡å‹ä¿å­˜ä¸åŠ è½½

### æ£€æŸ¥ç‚¹ç»“æ„

è®­ç»ƒä¼šåœ¨ `out-shakespeare-xl-deepspeed/` ç›®å½•ä¸‹ä¿å­˜æ£€æŸ¥ç‚¹ï¼š

```
out-shakespeare-xl-deepspeed/
â”œâ”€â”€ iter_5/                          # ç¬¬5æ­¥çš„æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ mp_rank_00_model_states.pt   # GPU 0 çš„æ¨¡å‹çŠ¶æ€
â”‚   â”œâ”€â”€ mp_rank_01_model_states.pt   # GPU 1 çš„æ¨¡å‹çŠ¶æ€
â”‚   â”œâ”€â”€ mp_rank_02_model_states.pt   # GPU 2 çš„æ¨¡å‹çŠ¶æ€
â”‚   â”œâ”€â”€ mp_rank_03_model_states.pt   # GPU 3 çš„æ¨¡å‹çŠ¶æ€
â”‚   â”œâ”€â”€ zero_pp_rank_0_mp_rank_00_optim_states.pt  # ä¼˜åŒ–å™¨çŠ¶æ€
â”‚   â”œâ”€â”€ zero_pp_rank_1_mp_rank_01_optim_states.pt
â”‚   â”œâ”€â”€ zero_pp_rank_2_mp_rank_02_optim_states.pt
â”‚   â”œâ”€â”€ zero_pp_rank_3_mp_rank_03_optim_states.pt
â”‚   â””â”€â”€ latest                        # æŒ‡å‘æœ€æ–°æ£€æŸ¥ç‚¹çš„ç¬¦å·é“¾æ¥
â”‚
â”œâ”€â”€ iter_10/                         # ç¬¬10æ­¥çš„æ£€æŸ¥ç‚¹
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ iter_15/                         # ç¬¬15æ­¥çš„æ£€æŸ¥ç‚¹
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ final/                           # æœ€ç»ˆæ£€æŸ¥ç‚¹
    â””â”€â”€ ...
```

### ä¿å­˜æ£€æŸ¥ç‚¹

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­è‡ªåŠ¨ä¿å­˜
if iter_num % eval_interval == 0:
    losses = estimate_loss()
    
    if losses['val'] < best_val_loss or always_save_checkpoint:
        best_val_loss = losses['val']
        if iter_num > 0:
            # DeepSpeed ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæ‰€æœ‰è¿›ç¨‹éƒ½å‚ä¸ï¼‰
            model_engine.save_checkpoint(
                out_dir, 
                tag=f"iter_{iter_num}"
            )
            if master_process:
                print(f"saving checkpoint to {out_dir}")

# è®­ç»ƒç»“æŸä¿å­˜æœ€ç»ˆæ¨¡å‹
model_engine.save_checkpoint(out_dir, tag="final")
```

### åŠ è½½æ£€æŸ¥ç‚¹

#### æ–¹æ³•1ï¼šä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

```python
# åœ¨ train_deepspeed.py ä¸­æ·»åŠ 
resume_from_checkpoint = "out-shakespeare-xl-deepspeed/iter_15"

if resume_from_checkpoint:
    # åŠ è½½æ£€æŸ¥ç‚¹
    _, client_state = model_engine.load_checkpoint(
        resume_from_checkpoint,
        load_optimizer_states=True,
        load_lr_scheduler_states=False
    )
    
    # æ¢å¤è®­ç»ƒçŠ¶æ€
    if client_state:
        iter_num = client_state.get('iter_num', 0)
        best_val_loss = client_state.get('best_val_loss', 1e9)
        print(f"Resumed from iteration {iter_num}")
```

#### æ–¹æ³•2ï¼šåŠ è½½æ¨¡å‹ç”¨äºæ¨ç†

```python
import torch
from model import GPT, GPTConfig

# 1. åˆ›å»ºæ¨¡å‹
config = GPTConfig(
    n_layer=48,      # GPT-2 XL
    n_head=25,
    n_embd=1600,
    block_size=1024,
    vocab_size=50257
)
model = GPT(config)

# 2. åŠ è½½ DeepSpeed æ£€æŸ¥ç‚¹
checkpoint_path = "out-shakespeare-xl-deepspeed/final"

# ä½¿ç”¨ DeepSpeed çš„åŠ è½½å‡½æ•°
from deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint

state_dict = load_state_dict_from_zero_checkpoint(model, checkpoint_path)
model.load_state_dict(state_dict)

# 3. ä½¿ç”¨æ¨¡å‹
model.eval()
model.to('cuda')

# æ¨ç†
with torch.no_grad():
    output = model.generate(...)
```

#### æ–¹æ³•3ï¼šè½¬æ¢ä¸ºæ ‡å‡†PyTorchæ ¼å¼

```bash
# ä½¿ç”¨ DeepSpeed æä¾›çš„å·¥å…·
python /path/to/deepspeed/utils/zero_to_fp32.py \
    out-shakespeare-xl-deepspeed/final \
    output.pt

# è¿™ä¼šç”Ÿæˆä¸€ä¸ªæ ‡å‡†çš„ PyTorch checkpoint
# å¯ä»¥ç›´æ¥ç”¨ torch.load() åŠ è½½
```

---

## æ€§èƒ½ä¼˜åŒ–

### GPU åˆ©ç”¨ç‡ä¼˜åŒ–

#### 1. è°ƒæ•´ batch size

```python
# å¦‚æœGPUåˆ©ç”¨ç‡ä½äº80%
# å°è¯•å¢åŠ  batch_size
batch_size = 2  # ä»1å¢åŠ åˆ°2
gradient_accumulation_steps = 16  # ç›¸åº”å‡å°‘ä»¥ä¿æŒæœ‰æ•ˆbatch size

# å¦‚æœGPUå†…å­˜å……è¶³
batch_size = 4
gradient_accumulation_steps = 8
```

#### 2. å¯ç”¨ overlap_comm

```json
// ds_config_zero2.json
{
  "zero_optimization": {
    "overlap_comm": true,  // â† é‡å é€šä¿¡å’Œè®¡ç®—
    "contiguous_gradients": true
  }
}
```

#### 3. ä¼˜åŒ–æ•°æ®åŠ è½½

```python
# ä½¿ç”¨æ›´å¤šçš„æ•°æ®åŠ è½½worker
from torch.utils.data import DataLoader

dataloader = DataLoader(
    dataset,
    batch_size=batch_size,
    num_workers=4,      # å¢åŠ workeræ•°é‡
    pin_memory=True,    # å¯ç”¨pin memory
    prefetch_factor=2   # é¢„å–æ•°æ®
)
```

### è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–

#### 1. å‡å°‘è¯„ä¼°é¢‘ç‡

```python
# å¦‚æœä¸éœ€è¦é¢‘ç¹ç›‘æ§
eval_interval = 100   # ä»5å¢åŠ åˆ°100
eval_iters = 10       # ä»20å‡å°‘åˆ°10
```

#### 2. ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆGradient Checkpointingï¼‰

```python
# åœ¨æ¨¡å‹åˆå§‹åŒ–å
model.gradient_checkpointing_enable()

# ä¼˜ç‚¹ï¼šæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨
# ç¼ºç‚¹ï¼šè®­ç»ƒé€Ÿåº¦é™ä½çº¦20-30%
```

#### 3. ç¼–è¯‘æ¨¡å‹ï¼ˆPyTorch 2.0+ï¼‰

```python
# æ³¨æ„ï¼šéœ€è¦ç¦ç”¨ DeepSpeed æˆ–ä½¿ç”¨å…¼å®¹æ¨¡å¼
import torch._dynamo

model = torch.compile(model, mode='reduce-overhead')

# å¯èƒ½æå‡10-30%çš„é€Ÿåº¦
# ä½†ä¸ DeepSpeed çš„å…¼å®¹æ€§éœ€è¦æµ‹è¯•
```

### å†…å­˜ä¼˜åŒ–

#### 1. é™ä½åºåˆ—é•¿åº¦

```python
block_size = 512   # ä»1024é™ä½åˆ°512

# å†…å­˜èŠ‚çœ: ~50%
# ä½†ä¼šå½±å“æ¨¡å‹è´¨é‡
```

#### 2. ä½¿ç”¨ CPU Offloadingï¼ˆZeRO-3ï¼‰

```json
// åˆ‡æ¢åˆ° ZeRO-3 é…ç½®
{
  "zero_optimization": {
    "stage": 3,
    "offload_optimizer": {
      "device": "cpu",
      "pin_memory": true
    },
    "offload_param": {
      "device": "cpu",
      "pin_memory": true
    }
  }
}
```

#### 3. æ¿€æ´»å€¼æ£€æŸ¥ç‚¹

```python
# åœ¨æ¨¡å‹é…ç½®ä¸­
model_config = GPTConfig(
    ...
    gradient_checkpointing=True  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
)
```

---

## å¸¸è§é—®é¢˜

### Q1: OOM (Out of Memory) é”™è¯¯

**é—®é¢˜ï¼š**
```
torch.cuda.OutOfMemoryError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **å‡å° batch_size**
```python
batch_size = 1  # å·²ç»æ˜¯æœ€å°å€¼
gradient_accumulation_steps = 64  # å¢åŠ æ¢¯åº¦ç´¯ç§¯
```

2. **å‡å°åºåˆ—é•¿åº¦**
```python
block_size = 512  # ä»1024å‡å°
```

3. **å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹**
```python
model.gradient_checkpointing_enable()
```

4. **ä½¿ç”¨æ›´å¤šGPU**
```bash
deepspeed --num_gpus=8 train_deepspeed.py  # ä»4å¢åŠ åˆ°8
```

5. **åˆ‡æ¢åˆ° ZeRO-3**
```python
deepspeed_config = 'ds_config_zero3.json'
```

### Q2: NCCL é€šä¿¡é”™è¯¯

**é—®é¢˜ï¼š**
```
[rank0]:[W...] NCCL communication timeout
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **è®¾ç½®ç¯å¢ƒå˜é‡**
```bash
export NCCL_DEBUG=INFO
export NCCL_TIMEOUT=1800  # 30åˆ†é’Ÿ
```

2. **æ£€æŸ¥GPUäº’è”**
```bash
nvidia-smi topo -m  # æŸ¥çœ‹GPUæ‹“æ‰‘
```

3. **ä½¿ç”¨æ›´ç¨³å®šçš„é€šä¿¡åç«¯**
```bash
export NCCL_IB_DISABLE=1  # ç¦ç”¨InfiniBand
export NCCL_P2P_DISABLE=1  # ç¦ç”¨P2Pï¼ˆå¦‚æœæœ‰é—®é¢˜ï¼‰
```

### Q3: è®­ç»ƒé€Ÿåº¦æ…¢

**é—®é¢˜ï¼š**
è®­ç»ƒé€Ÿåº¦è¿œä½äºé¢„æœŸï¼ˆ>1s/iterationï¼‰

**è¯Šæ–­å’Œè§£å†³ï¼š**

1. **æ£€æŸ¥GPUåˆ©ç”¨ç‡**
```bash
watch -n 1 nvidia-smi

# å¦‚æœGPUåˆ©ç”¨ç‡<80%ï¼Œå¯èƒ½æ˜¯ï¼š
# - Batch size å¤ªå°
# - æ•°æ®åŠ è½½ç“¶é¢ˆ
# - CPUæˆä¸ºç“¶é¢ˆ
```

2. **ä¼˜åŒ–æ•°æ®åŠ è½½**
```python
# å¢åŠ num_workers
num_workers = 4

# ä½¿ç”¨pin_memory
pin_memory = True
```

3. **å‡å°‘è¯„ä¼°é¢‘ç‡**
```python
eval_interval = 100  # å¢å¤§interval
eval_iters = 10     # å‡å°‘eval_iters
```

### Q4: è¯„ä¼°åè®­ç»ƒhangä½

**é—®é¢˜ï¼š**
è®­ç»ƒåœ¨ `step 5` æˆ– `step 10` ååœæ­¢å“åº”

**è§£å†³æ–¹æ¡ˆï¼š**

ä»£ç å·²ä¿®å¤ã€‚ç¡®ä¿ï¼š
1. æ‰€æœ‰è¿›ç¨‹éƒ½æ‰§è¡Œ `estimate_loss()`
2. è¯„ä¼°ç§å­æ­£ç¡®è®¾ç½®å’Œæ¢å¤
3. ä½¿ç”¨æ­£ç¡®çš„ `all_reduce` æ“ä½œ

å¦‚æœä»æœ‰é—®é¢˜ï¼Œå¯ä»¥ç¦ç”¨è¯„ä¼°ï¼š
```python
eval_interval = 999999  # ç¦ç”¨ä¸­é—´è¯„ä¼°
```

### Q5: æ£€æŸ¥ç‚¹æ— æ³•åŠ è½½

**é—®é¢˜ï¼š**
```
Error loading checkpoint from ...
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **æ£€æŸ¥æ£€æŸ¥ç‚¹å®Œæ•´æ€§**
```bash
ls -lh out-shakespeare-xl-deepspeed/iter_5/
# åº”è¯¥çœ‹åˆ°æ‰€æœ‰GPUçš„æ–‡ä»¶
```

2. **ä½¿ç”¨æ­£ç¡®çš„åŠ è½½æ–¹æ³•**
```python
# ç¡®ä¿ä½¿ç”¨ DeepSpeed çš„åŠ è½½å‡½æ•°
_, client_state = model_engine.load_checkpoint(checkpoint_path)
```

3. **è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼**
```bash
python deepspeed/utils/zero_to_fp32.py checkpoint_dir output.pt
```

---

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯

#### æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦

```python
from torch.optim.lr_scheduler import CosineAnnealingLR

# åˆ›å»ºscheduler
scheduler = CosineAnnealingLR(
    optimizer,
    T_max=max_iters,
    eta_min=learning_rate * 0.1
)

# åœ¨è®­ç»ƒå¾ªç¯ä¸­
for iter_num in range(max_iters):
    # ... è®­ç»ƒä»£ç  ...
    
    # æ›´æ–°å­¦ä¹ ç‡
    scheduler.step()
    
    # æ‰“å°å½“å‰å­¦ä¹ ç‡
    if master_process and iter_num % 10 == 0:
        current_lr = optimizer.param_groups[0]['lr']
        print(f"Learning rate: {current_lr:.2e}")
```

#### å®ç°æ—©åœï¼ˆEarly Stoppingï¼‰

```python
# åœ¨è®­ç»ƒå¾ªç¯å‰
patience = 5
patience_counter = 0
best_val_loss = 1e9

# åœ¨è¯„ä¼°å
if iter_num % eval_interval == 0:
    losses = estimate_loss()
    
    if losses['val'] < best_val_loss:
        best_val_loss = losses['val']
        patience_counter = 0
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        model_engine.save_checkpoint(out_dir, tag="best")
    else:
        patience_counter += 1
    
    if patience_counter >= patience:
        if master_process:
            print(f"Early stopping triggered at iteration {iter_num}")
        break
```

#### é›†æˆ Weights & Biases (wandb)

```python
import wandb

# åˆå§‹åŒ–wandbï¼ˆåªåœ¨masterè¿›ç¨‹ï¼‰
if master_process:
    wandb.init(
        project="gpt2-xl-finetuning",
        config=config,
        name=wandb_run_name
    )

# åœ¨è®­ç»ƒå¾ªç¯ä¸­è®°å½•
if master_process and iter_num % 10 == 0:
    wandb.log({
        'train/loss': train_loss,
        'train/lr': current_lr,
        'train/iter': iter_num,
        'gpu/memory_allocated': torch.cuda.memory_allocated() / 1e9,
    })

# åœ¨è¯„ä¼°æ—¶è®°å½•
if master_process:
    wandb.log({
        'eval/train_loss': losses['train'],
        'eval/val_loss': losses['val'],
        'eval/perplexity': math.exp(losses['val']),
    })
```

### å¤šæ•°æ®é›†è®­ç»ƒ

```python
# å®šä¹‰å¤šä¸ªæ•°æ®é›†
datasets = {
    'shakespeare': 'data/shakespeare',
    'openwebtext': 'data/openwebtext',
}

# è½®æµé‡‡æ ·
dataset_names = list(datasets.keys())
dataset_weights = [0.3, 0.7]  # Shakespeare 30%, OpenWebText 70%

def get_batch_multi_dataset(split):
    # æ ¹æ®æƒé‡éšæœºé€‰æ‹©æ•°æ®é›†
    dataset_name = np.random.choice(dataset_names, p=dataset_weights)
    data_dir = datasets[dataset_name]
    
    # åŠ è½½æ•°æ®
    if split == 'train':
        data = np.memmap(os.path.join(data_dir, 'train.bin'), 
                        dtype=np.uint16, mode='r')
    else:
        data = np.memmap(os.path.join(data_dir, 'val.bin'), 
                        dtype=np.uint16, mode='r')
    
    # ... å…¶ä½™ä»£ç åŒ get_batch ...
    return x, y
```

### å¢é‡è®­ç»ƒï¼ˆContinual Learningï¼‰

```python
# ç¬¬ä¸€é˜¶æ®µï¼šåœ¨Shakespeareä¸Šè®­ç»ƒ
init_from = 'gpt2-xl'
dataset = 'shakespeare'
max_iters = 1000
# ... è®­ç»ƒ ...

# ä¿å­˜é˜¶æ®µ1æ¨¡å‹
model_engine.save_checkpoint(out_dir, tag="stage1")

# ç¬¬äºŒé˜¶æ®µï¼šåœ¨å¦ä¸€ä¸ªæ•°æ®é›†ä¸Šç»§ç»­è®­ç»ƒ
dataset = 'openwebtext'
learning_rate = learning_rate * 0.1  # é™ä½å­¦ä¹ ç‡
max_iters = 500

# ä»é˜¶æ®µ1åŠ è½½
model_engine.load_checkpoint(
    os.path.join(out_dir, "stage1"),
    load_optimizer_states=False  # é‡æ–°åˆå§‹åŒ–ä¼˜åŒ–å™¨
)

# ... ç»§ç»­è®­ç»ƒ ...
```

---

## æ€§èƒ½åŸºå‡†æµ‹è¯•

### æ ‡å‡†é…ç½®æ€§èƒ½

åœ¨ 4x V100-32GB ä¸Šçš„æµ‹è¯•ç»“æœï¼š

| é…ç½® | é€Ÿåº¦ | GPUå†…å­˜ | æœ‰æ•ˆBatch | å¤‡æ³¨ |
|------|------|---------|----------|------|
| ZeRO-2, BS=1, GA=32 | 303ms/iter | 15.5GB | 128 | âœ… æ¨è |
| ZeRO-2, BS=2, GA=16 | 450ms/iter | 24GB | 128 | é«˜åˆ©ç”¨ç‡ |
| ZeRO-3, BS=1, GA=32 | 1500ms/iter | 12GB | 128 | å†…å­˜ä¼˜åŒ– |
| DDP, BS=1, GA=32 | OOM | 35GB+ | - | âŒ ä¸å¯è¡Œ |

### ä¸åŒGPUé…ç½®å¯¹æ¯”

| GPUå‹å· | æ•°é‡ | å†…å­˜/GPU | æ¨èé…ç½® | é¢„æœŸé€Ÿåº¦ |
|---------|------|----------|---------|---------|
| V100 32GB | 4 | 15-16GB | ZeRO-2 | ~300ms |
| A100 40GB | 4 | 18-20GB | ZeRO-2 | ~200ms |
| A100 80GB | 2 | 25-28GB | ZeRO-2 | ~250ms |
| RTX 3090 24GB | 8 | 18-20GB | ZeRO-2 | ~350ms |

---

## æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **ä»å°æ•°æ®é›†å¼€å§‹**
   - å…ˆåœ¨å°æ•°æ®é›†ï¼ˆå¦‚Shakespeareï¼‰ä¸ŠéªŒè¯æµç¨‹
   - ç¡®è®¤è®­ç»ƒæ­£å¸¸åå†ç”¨å¤§æ•°æ®é›†

2. **æ¸è¿›å¼è®­ç»ƒ**
   ```python
   # ç¬¬ä¸€æ¬¡ï¼šå°‘é‡è¿­ä»£éªŒè¯
   max_iters = 10
   
   # éªŒè¯æˆåŠŸåï¼šå®Œæ•´è®­ç»ƒ
   max_iters = 10000
   ```

3. **ç›‘æ§GPUçŠ¶æ€**
   ```bash
   # å®æ—¶ç›‘æ§
   watch -n 1 nvidia-smi
   
   # è®°å½•æ—¥å¿—
   nvidia-smi dmon -s mu > gpu_usage.log &
   ```

4. **å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹**
   ```python
   eval_interval = 100  # æ¯100æ­¥è¯„ä¼°å’Œä¿å­˜
   always_save_checkpoint = True
   ```

5. **ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶**
   ```bash
   # è®°å½•è®­ç»ƒé…ç½®
   git add train_deepspeed.py ds_config_zero2.json
   git commit -m "Training run: $(date)"
   ```

### âŒ é¿å…åšæ³•

1. **ä¸è¦åœ¨ç”Ÿäº§æ•°æ®ä¸Šç›´æ¥å®éªŒ**
   - å…ˆç”¨å°æ•°æ®é›†éªŒè¯
   - é¿å…æµªè´¹è®¡ç®—èµ„æº

2. **ä¸è¦å¿½ç•¥è­¦å‘Šä¿¡æ¯**
   ```python
   # NCCLè­¦å‘Šå¯èƒ½é¢„ç¤ºé—®é¢˜
   # åŠæ—¶æ£€æŸ¥å’Œå¤„ç†
   ```

3. **ä¸è¦è¿‡åº¦ä¼˜åŒ–è¶…å‚æ•°**
   - é»˜è®¤é…ç½®å·²ç»å¾ˆå¥½
   - å…ˆç¡®ä¿è®­ç»ƒç¨³å®šï¼Œå†ä¼˜åŒ–

4. **ä¸è¦ç¦ç”¨æ£€æŸ¥ç‚¹ä¿å­˜**
   ```python
   always_save_checkpoint = True  # ä¿æŒTrue
   ```

5. **ä¸è¦æ··ç”¨ä¸åŒç‰ˆæœ¬**
   - PyTorchã€DeepSpeedç‰ˆæœ¬è¦åŒ¹é…
   - è®°å½•ä¾èµ–ç‰ˆæœ¬

---

## æ•…éšœæ’é™¤æµç¨‹

```
é‡åˆ°é—®é¢˜
    â†“
æŸ¥çœ‹é”™è¯¯ä¿¡æ¯
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é”™è¯¯ç±»å‹ï¼Ÿ         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. OOM              â”‚ â†’ å‡å°batch_size/block_size
â”‚ 2. NCCLé”™è¯¯         â”‚ â†’ æ£€æŸ¥ç½‘ç»œ/GPUäº’è”
â”‚ 3. åŠ è½½é”™è¯¯         â”‚ â†’ æ£€æŸ¥æ£€æŸ¥ç‚¹æ–‡ä»¶
â”‚ 4. è®­ç»ƒhang         â”‚ â†’ æ£€æŸ¥è¯„ä¼°å‡½æ•°/åŒæ­¥
â”‚ 5. é€Ÿåº¦æ…¢           â”‚ â†’ ä¼˜åŒ–æ•°æ®åŠ è½½/GPUåˆ©ç”¨ç‡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
æŸ¥çœ‹æœ¬æ–‡æ¡£ç›¸å…³ç« èŠ‚
    â†“
å°è¯•è§£å†³æ–¹æ¡ˆ
    â†“
é—®é¢˜è§£å†³ï¼Ÿ
    â”œâ”€ æ˜¯ â†’ ç»§ç»­è®­ç»ƒ âœ…
    â””â”€ å¦ â†’ æŸ¥çœ‹æ—¥å¿—/å¯»æ±‚å¸®åŠ©
```

---

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [DeepSpeedå®˜æ–¹æ–‡æ¡£](https://www.deepspeed.ai/)
- [DeepSpeed ZeROæ•™ç¨‹](https://www.deepspeed.ai/tutorials/zero/)
- [PyTorchåˆ†å¸ƒå¼è®­ç»ƒ](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
- [nanoGPTé¡¹ç›®](https://github.com/karpathy/nanoGPT)

### è®ºæ–‡

- [ZeROè®ºæ–‡](https://arxiv.org/abs/1910.02054) - ZeRO: Memory Optimizations Toward Training Trillion Parameter Models
- [GPT-2è®ºæ–‡](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [Mixed Precision Training](https://arxiv.org/abs/1710.03740)

### ç›¸å…³é¡¹ç›®

- [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) - å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹è®­ç»ƒ
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [FlashAttention](https://github.com/Dao-AILab/flash-attention) - é«˜æ•ˆæ³¨æ„åŠ›å®ç°

---

## æ›´æ–°æ—¥å¿—

### 2025-10-27
- âœ… åˆå§‹ç‰ˆæœ¬
- âœ… å®Œæ•´çš„DeepSpeed ZeRO-2å®ç°
- âœ… åˆ†å¸ƒå¼è¯„ä¼°åŠŸèƒ½
- âœ… æ£€æŸ¥ç‚¹ä¿å­˜ä¼˜åŒ–
- âœ… è¯¦ç»†æ–‡æ¡£å’Œç¤ºä¾‹

---

## è”ç³»å’Œæ”¯æŒ

å¦‚æœæ‚¨é‡åˆ°é—®é¢˜æˆ–æœ‰å»ºè®®ï¼š

1. **æŸ¥çœ‹æ–‡æ¡£** - å¤§å¤šæ•°é—®é¢˜åœ¨æœ¬æ–‡æ¡£ä¸­éƒ½æœ‰è§£ç­”
2. **æ£€æŸ¥æ—¥å¿—** - é”™è¯¯ä¿¡æ¯é€šå¸¸åŒ…å«è§£å†³çº¿ç´¢
3. **GitHub Issues** - æäº¤é—®é¢˜åˆ°é¡¹ç›®ä»“åº“
4. **ç¤¾åŒºè®¨è®º** - DeepSpeed Discord/è®ºå›

---

**ğŸ‰ ç¥æ‚¨è®­ç»ƒæˆåŠŸï¼**

è®°ä½ï¼š
- ä»å°å¼€å§‹ï¼Œé€æ­¥æ‰©å±•
- ç›‘æ§è®­ç»ƒè¿‡ç¨‹
- å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
- è®°å½•å®éªŒé…ç½®

Happy Training! ğŸš€

